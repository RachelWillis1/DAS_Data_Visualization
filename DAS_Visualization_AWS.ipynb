{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2484266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import joblib\n",
    "import pathlib\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from obspy import UTCDateTime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c899dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240 .hdf5 files are in list to be processed.\n"
     ]
    }
   ],
   "source": [
    "# Load channels list\n",
    "with open(\"channels_to_read_new.json\", 'r') as f:\n",
    "    channels_to_read_new = json.load(f)\n",
    "\n",
    "# File Paths\n",
    "data_dir = (\"DAS_data/\")\n",
    "\n",
    "# Load and Sort File List\n",
    "nr_files_to_load = 3\n",
    "nr_files_to_process = nr_files_to_load - 2\n",
    "files_list = sorted(glob.glob(data_dir + \"*.hdf5\"))\n",
    "#files_list = files_list[:9] #Optional to limit number of data files being plotted\n",
    "nr_files = len(files_list)\n",
    "\n",
    "print(f\"{nr_files} .hdf5 files are in list to be processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a4178fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_h5_idas2_data(file):\n",
    "    \"\"\"\n",
    "    Looks at a native silixa iDAS .h5 file and returns some fields from the\n",
    "    metadata in the header\n",
    "    \"\"\"\n",
    "    file = pathlib.Path(file)\n",
    "    with h5py.File(file, \"r\") as f:\n",
    "        dset = f['raw_das_data']\n",
    "        # dtype = dset.dtype\n",
    "\n",
    "        ddims = dset.shape\n",
    "        nsamp = ddims[0]\n",
    "        # nchan = ddims[1]\n",
    "\n",
    "        metadata = dict(dset.attrs)\n",
    "        starttime = UTCDateTime(str(metadata[\"starttime\"]))\n",
    "\n",
    "        fs = int(metadata[\"sampling_frequency_Hz\"])\n",
    "        dx = float(metadata[\"spatial_resolution_m\"])\n",
    "        d0 = float(metadata[\"start_distance_m\"])\n",
    "        endtime = starttime + ((nsamp-1)/float(fs))\n",
    "\n",
    "        return starttime, endtime, fs, dx, d0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b1686d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_idas2_h5_file(file, stream=True, channels=[0, -1], auxiliary=True):\n",
    "    file = pathlib.Path(file)\n",
    "    with h5py.File(file, \"r\") as f:\n",
    "        dset = f['raw_das_data']\n",
    "\n",
    "        ddims = dset.shape\n",
    "        nsamp = ddims[0]\n",
    "\n",
    "        metadata = dict(dset.attrs)\n",
    "        starttime = UTCDateTime(str(metadata[\"starttime\"]))\n",
    "\n",
    "        fs = int(metadata[\"sampling_frequency_Hz\"])\n",
    "        dx = float(metadata[\"spatial_resolution_m\"])\n",
    "        d0 = float(metadata[\"start_distance_m\"])\n",
    "\n",
    "        if channels == [0, -1]:\n",
    "            data = np.array(dset[:, :])\n",
    "        elif len(channels) > 2:\n",
    "            data = np.array(dset[:, channels])\n",
    "        else:\n",
    "            data = np.array(dset[:, channels[0]:channels[-1]])\n",
    "\n",
    "        if stream:\n",
    "            st = Stream()\n",
    "            trace_l = ((\"sampling_rate\", int(fs)),\n",
    "                       (\"delta\", 1./int(fs)),\n",
    "                       (\"calib\", 1.),\n",
    "                       (\"npts\", int(nsamp)),\n",
    "                       (\"network\", \"XS\"),\n",
    "                       (\"station\", \"\"),\n",
    "                       (\"starttime\", starttime))\n",
    "            trace_dict = {key: value for (key, value) in trace_l}\n",
    "\n",
    "            for i in range(data.shape[1]):\n",
    "                tr = obspy.Trace(data=data[:, i], header=trace_dict)\n",
    "                tr.stats.distance = d0 + (i+channels[0])*dx\n",
    "                tr.stats.channel = \"ESN\"\n",
    "                tr.stats.station = \"D\" + \"{0:05d}\".format(i+channels[0])\n",
    "                st.__iadd__(tr)\n",
    "\n",
    "            if auxiliary:\n",
    "                st.metadata = metadata\n",
    "\n",
    "            return(st)\n",
    "        else:\n",
    "            return(data, channels, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19a4cfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_idas2_h5_files(files, as_stream=False, stream=True, channels=[0, -1],\n",
    "                        auxiliary=True, merge=True, sort=True):\n",
    "    \"\"\"Reader function for idas2 .hdf5 files. Subroutine called by das_reader,\n",
    "    so for details, please look at das_reader.\n",
    "\n",
    "    Args:\n",
    "        files ([type]): [description]\n",
    "        as_stream (bool, optional): [description]. Defaults to False.\n",
    "        stream (bool, optional): [description]. Defaults to True.\n",
    "        channels (list, optional): [description]. Defaults to [0, -1].\n",
    "        auxiliary (bool, optional): [description]. Defaults to True.\n",
    "        merge (bool, optional): [description]. Defaults to True.\n",
    "        sort (bool, optional): [description]. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(files, list):\n",
    "        files = [files]\n",
    "\n",
    "    for i in range(len(files)-1):\n",
    "        starttime0, endtime0, fs0, dx0, d00 = peak_h5_idas2_data(files[i])\n",
    "        starttime1, endtime1, fs1, dx1, d01 = peak_h5_idas2_data(files[i+1])\n",
    "\n",
    "        if (fs0 == fs1) & (dx0 == dx1) & (d00 == d01):\n",
    "            pass\n",
    "        else:\n",
    "            print(\"Warning: Different acquisition parameters. Skipping file: {}\".format(files[i]))\n",
    "            a.write(str(files[i]));a.write(' - Warning: Different acquisition parameters');a.write('\\n')\n",
    "            continue\n",
    "\n",
    "        # if starttime1 == endtime0+(1./fs1):\n",
    "        #     pass\n",
    "        # else:\n",
    "        #     print(\"Warning: Misaligned data (gaps or overlap). Skipping file: {}\".format(files[i]))\n",
    "        #     a.write(str(files[i]));a.write(' - Warning: Misaligned data');a.write('\\n')\n",
    "        #     continue\n",
    "\n",
    "    if as_stream:\n",
    "        stream = True\n",
    "        # WORKING WITH STREAM OBJECTS DIRECTLY (one stream per file)\n",
    "        st = Stream()\n",
    "        iter_ = (i for i in range(len(files)))\n",
    "\n",
    "        for file in files:\n",
    "            i = next(iter_)\n",
    "            st_tmp = read_idas2_h5_file(\n",
    "                file, stream=stream, channels=channels, auxiliary=auxiliary)\n",
    "            st += st_tmp\n",
    "            if i == 0:\n",
    "                st.metadata = st_tmp.metadata\n",
    "\n",
    "        if merge:\n",
    "            if not st.get_gaps():\n",
    "                st.merge(method=1).sort()\n",
    "            else:\n",
    "                warnings.warn(\"Gaps or overlap in the data. Returned stream\"\n",
    "                              + \"object is not merged!\", UserWarning)\n",
    "                if True:\n",
    "                    st.print_gaps()\n",
    "        if sort:\n",
    "            st.sort()\n",
    "        return st\n",
    "\n",
    "    else:\n",
    "        iter_ = (i for i in range(len(files)))\n",
    "        for file in files:\n",
    "            i = next(iter_)\n",
    "            if i == 0:\n",
    "                data, channels, metadata = read_idas2_h5_file(\n",
    "                    file, stream=False, channels=channels, auxiliary=auxiliary)\n",
    "\n",
    "            else:\n",
    "                data_tmp, _, _ = read_idas2_h5_file(\n",
    "                    file, stream=False, channels=channels, auxiliary=auxiliary)\n",
    "                data = np.vstack([data, data_tmp])\n",
    "\n",
    "        if stream:\n",
    "            if not merge:\n",
    "                warnings.warn(\n",
    "                    \"merge=True was set because of working with the numpy\"\n",
    "                    + \"arrays\", UserWarning)\n",
    "\n",
    "            starttime = UTCDateTime(str(metadata[\"starttime\"]))\n",
    "            fs = int(metadata[\"sampling_frequency_Hz\"])\n",
    "            dx = float(metadata[\"spatial_resolution_m\"])\n",
    "            d0 = float(metadata[\"start_distance_m\"])\n",
    "            # endtime = starttime + ((nsamp-1)/float(fs))\n",
    "\n",
    "            st = Stream()\n",
    "            trace_l = ((\"sampling_rate\", int(fs)),\n",
    "                       (\"delta\", 1./int(fs)),\n",
    "                       (\"calib\", 1.),\n",
    "                       (\"npts\", int(data.shape[0])),\n",
    "                       (\"network\", \"XS\"),\n",
    "                       (\"station\", \"\"),\n",
    "                       (\"starttime\", starttime))\n",
    "            trace_dict = {key: value for (key, value) in trace_l}\n",
    "\n",
    "\n",
    "            # Added for correct channel numbers when using fancy indexing\n",
    "            for i in range(data.shape[1]):\n",
    "                tr = obspy.Trace(data=data[:, i], header=trace_dict)\n",
    "                if len(channels) == 2:\n",
    "                    tr.stats.distance = d0 + (i+channels[0])*dx\n",
    "                    tr.stats.channel = \"ESN\"\n",
    "                    tr.stats.station = \"D\" + \"{0:05d}\".format(i+channels[0])\n",
    "                elif len(channels) > 2:\n",
    "                    tr.stats.distance = d0 + (channels[i])*dx\n",
    "                    tr.stats.station = \"D\" + \"{0:05d}\".format(channels[i])\n",
    "                st.__iadd__(tr)\n",
    "                \n",
    "\n",
    "            # for i in range(data.shape[1]):\n",
    "            #     tr = obspy.Trace(data=data[:, i], header=trace_dict)\n",
    "            #     tr.stats.distance = d0 + (i+channels[0])*dx\n",
    "            #     tr.stats.channel = \"ESN\"\n",
    "            #     tr.stats.station = \"D\" + \"{0:05d}\".format(i+channels[0])\n",
    "            #     st.__iadd__(tr)\n",
    "\n",
    "            if auxiliary:\n",
    "                st.metadata = metadata\n",
    "                \n",
    "\n",
    "            if sort:\n",
    "                st.sort()\n",
    "            return(st)\n",
    "\n",
    "        else:\n",
    "            return(data, channels, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7f9f758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def das_reader(files, auxiliary=True, sort=True, merge=True,\n",
    "               stream=True, as_stream=False,\n",
    "               channels=[0, -1], h5type='native', debug=False):\n",
    "    \"\"\"\n",
    "    Reader function to read in iDAS data into either a numpy array or an\n",
    "    obspy stream object. Default values should be: auxiliary=True,\n",
    "    as_stream=False, and stream=True.\n",
    "    :type files: list\n",
    "    :param files: List of files to read\n",
    "    :type auxiliary: bool\n",
    "    :param auxiliary: If metadata (header) should be read in and saved to\n",
    "    st.metadata\n",
    "    :type sort: bool\n",
    "    :param sort: If stream should be sorted by station\n",
    "    :type merge: bool\n",
    "    :param merge: If the stream object should be merged or not before returning\n",
    "    :type strean: bool\n",
    "    :param stream: If True, the function will return an obspy Stream object.\n",
    "    If False, will return data, channels, metadata, where data is the read in\n",
    "    data as 2d numpy array\n",
    "    :type as_stream: bool\n",
    "    :param as_stream: Decide how to read in and handle the data inside the\n",
    "    reader. default to False, but if h5type is asdf, this will automatically\n",
    "    be set to True. Same if there are gaps in the data, it will fall back to\n",
    "    as_stream=True, because the matrix/numpy version can not handle gaps due to\n",
    "    lacking of timestamping in numpy arrays\n",
    "    :type channels: list of 2 values\n",
    "    :param channels: Slice of channels to be read in. If default [0,-1], the\n",
    "    entire data will be read in. Otherwise arbitrary slicing would be possible\n",
    "    (eg. [20,50]). No interval slicing implemented yet (like [20:50:10] ).\n",
    "    This is on the ToDo.\n",
    "    :type h5type: str\n",
    "    :param h5type: The type of the data. Either native silixa h5 as from the\n",
    "    iDAS (h5type='native') or converted asdf data (h5type='asdf'). Now also\n",
    "    works for idas2 .hdf5 files: (h5type='ida2')\n",
    "    :type debug: bool\n",
    "    :param debug: optional print outputs\n",
    "    \"\"\"\n",
    "    if not isinstance(files, list):\n",
    "        files = [files]\n",
    "\n",
    "    if h5type not in ['asdf', 'native', 'idas2']:\n",
    "        sys.exit('Invalid h5type specified')\n",
    "    if debug:\n",
    "        print('\\U0001F50D Reading in: \\n', files)\n",
    "    if h5type == 'native':\n",
    "        if stream:\n",
    "            st = read_h5_native_files(files, auxiliary=auxiliary, sort=sort,\n",
    "                                      merge=merge, stream=stream,\n",
    "                                      as_stream=as_stream, channels=channels)\n",
    "            if debug:\n",
    "                print(\"\\U00002714 success\")\n",
    "            return st\n",
    "        else:\n",
    "            data, channels, metadata = read_h5_native_files(\n",
    "                files, auxiliary=auxiliary, sort=sort, merge=merge,\n",
    "                stream=stream, as_stream=as_stream, channels=channels\n",
    "                )\n",
    "            if debug:\n",
    "                print(\"\\U00002714 success\")\n",
    "            return (data, channels, metadata)\n",
    "\n",
    "    if h5type == 'idas2':\n",
    "        if stream:\n",
    "            st = read_idas2_h5_files(files, auxiliary=auxiliary, sort=sort,\n",
    "                                     merge=merge, stream=stream,\n",
    "                                     as_stream=as_stream, channels=channels)\n",
    "            if debug:\n",
    "                print(\"\\U00002714 success\")\n",
    "            return st\n",
    "        else:\n",
    "            data, channels, metadata = read_idas2_h5_files(\n",
    "                files, auxiliary=auxiliary, sort=sort, merge=merge,\n",
    "                stream=stream, as_stream=as_stream, channels=channels\n",
    "                )\n",
    "            if debug:\n",
    "                print(\"\\U00002714 success\")\n",
    "            return (data, channels, metadata)\n",
    "\n",
    "    if h5type == 'asdf':\n",
    "        st = read_h5_asdf_files(files, stream=stream, channels=channels,\n",
    "                                auxiliary=auxiliary, merge=merge, sort=sort)\n",
    "        if debug:\n",
    "            print(\"\\U00002714 success\")\n",
    "        return st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2032f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotChRange(data, fs=1000, clipPerc=None, time_axis='vertical', cmap='seismic', dpi=200, \n",
    "                title=None, outfile=None):\n",
    "    \"\"\"\n",
    "    Plot DAS profile for given channel range\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : numpy.ndarray\n",
    "        Input data in the t-x domain\n",
    "    fs : int\n",
    "        Sampling frequency in Hz\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Strain rate plot of DAS data.\n",
    "    \n",
    "    \"\"\"\n",
    "    if time_axis != 'vertical':\n",
    "        data = data.T\n",
    "\n",
    "    if clipPerc:\n",
    "        clip = np.percentile(np.absolute(data), clipPerc)\n",
    "        plt.figure(dpi=dpi)\n",
    "        plt.imshow(data, aspect='auto', interpolation='none',\n",
    "                   vmin=-clip, vmax=clip, cmap=cmap)\n",
    "    else:\n",
    "        plt.figure(dpi=dpi)\n",
    "        plt.imshow(data, aspect='auto', interpolation='none',\n",
    "                   vmin=-abs(data).max(), vmax=abs(data).max(),\n",
    "                   cmap=cmap)\n",
    "    plt.xlabel('Channel number')\n",
    "    plt.xticks(np.linspace(0, data.shape[1], 4), [int(val) for val in np.linspace(0, data.shape[1], 4)])\n",
    "    plt.ylabel('Time (s)')\n",
    "    plt.yticks(np.linspace(0, data.shape[0], 4), [int(val) for val in np.linspace(0, data.shape[0]/3000, 4)])\n",
    "\n",
    "    plt.colorbar(label='Strain rate (10$^{-9}$ s$^{-1}$)')\n",
    "    plt.tight_layout()\n",
    "    if title:\n",
    "        plt.title(title, fontsize=16)\n",
    "    if outfile:\n",
    "        plt.savefig(outfile, format='png')\n",
    "        plt.close('all')\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5563bd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing File ID: 0\n",
      "🔍 Reading in: \n",
      " ['/Users/rachelwillis/myDocuments/CSMresearch/Rhone_Glacier/Rhone_Glacier_AWS_Final/20200803_070000.000-20200803_090000.000/codes/input/DAS_data/idas2_UTC_20200803_070020.542_rhone1khz.hdf5', '/Users/rachelwillis/myDocuments/CSMresearch/Rhone_Glacier/Rhone_Glacier_AWS_Final/20200803_070000.000-20200803_090000.000/codes/input/DAS_data/idas2_UTC_20200803_070050.542_rhone1khz.hdf5', '/Users/rachelwillis/myDocuments/CSMresearch/Rhone_Glacier/Rhone_Glacier_AWS_Final/20200803_070000.000-20200803_090000.000/codes/input/DAS_data/idas2_UTC_20200803_070120.542_rhone1khz.hdf5']\n",
      "✔ success\n",
      "Processing File ID: 1\n",
      "🔍 Reading in: \n",
      " ['/Users/rachelwillis/myDocuments/CSMresearch/Rhone_Glacier/Rhone_Glacier_AWS_Final/20200803_070000.000-20200803_090000.000/codes/input/DAS_data/idas2_UTC_20200803_070050.542_rhone1khz.hdf5', '/Users/rachelwillis/myDocuments/CSMresearch/Rhone_Glacier/Rhone_Glacier_AWS_Final/20200803_070000.000-20200803_090000.000/codes/input/DAS_data/idas2_UTC_20200803_070120.542_rhone1khz.hdf5', '/Users/rachelwillis/myDocuments/CSMresearch/Rhone_Glacier/Rhone_Glacier_AWS_Final/20200803_070000.000-20200803_090000.000/codes/input/DAS_data/idas2_UTC_20200803_070150.542_rhone1khz.hdf5']\n",
      "✔ success\n",
      "Processing File ID: 2\n",
      "🔍 Reading in: \n",
      " ['/Users/rachelwillis/myDocuments/CSMresearch/Rhone_Glacier/Rhone_Glacier_AWS_Final/20200803_070000.000-20200803_090000.000/codes/input/DAS_data/idas2_UTC_20200803_070120.542_rhone1khz.hdf5', '/Users/rachelwillis/myDocuments/CSMresearch/Rhone_Glacier/Rhone_Glacier_AWS_Final/20200803_070000.000-20200803_090000.000/codes/input/DAS_data/idas2_UTC_20200803_070150.542_rhone1khz.hdf5', '/Users/rachelwillis/myDocuments/CSMresearch/Rhone_Glacier/Rhone_Glacier_AWS_Final/20200803_070000.000-20200803_090000.000/codes/input/DAS_data/idas2_UTC_20200803_070220.542_rhone1khz.hdf5']\n",
      "✔ success\n",
      "Processing File ID: 3\n",
      "🔍 Reading in: \n",
      " ['/Users/rachelwillis/myDocuments/CSMresearch/Rhone_Glacier/Rhone_Glacier_AWS_Final/20200803_070000.000-20200803_090000.000/codes/input/DAS_data/idas2_UTC_20200803_070150.542_rhone1khz.hdf5', '/Users/rachelwillis/myDocuments/CSMresearch/Rhone_Glacier/Rhone_Glacier_AWS_Final/20200803_070000.000-20200803_090000.000/codes/input/DAS_data/idas2_UTC_20200803_070220.542_rhone1khz.hdf5', '/Users/rachelwillis/myDocuments/CSMresearch/Rhone_Glacier/Rhone_Glacier_AWS_Final/20200803_070000.000-20200803_090000.000/codes/input/DAS_data/idas2_UTC_20200803_070250.542_rhone1khz.hdf5']\n",
      "✔ success\n",
      "Processing File ID: 4\n",
      "🔍 Reading in: \n",
      " ['/Users/rachelwillis/myDocuments/CSMresearch/Rhone_Glacier/Rhone_Glacier_AWS_Final/20200803_070000.000-20200803_090000.000/codes/input/DAS_data/idas2_UTC_20200803_070220.542_rhone1khz.hdf5', '/Users/rachelwillis/myDocuments/CSMresearch/Rhone_Glacier/Rhone_Glacier_AWS_Final/20200803_070000.000-20200803_090000.000/codes/input/DAS_data/idas2_UTC_20200803_070250.542_rhone1khz.hdf5', '/Users/rachelwillis/myDocuments/CSMresearch/Rhone_Glacier/Rhone_Glacier_AWS_Final/20200803_070000.000-20200803_090000.000/codes/input/DAS_data/idas2_UTC_20200803_070320.542_rhone1khz.hdf5']\n",
      "✔ success\n",
      "Processing File ID: 5\n",
      "🔍 Reading in: \n",
      " ['/Users/rachelwillis/myDocuments/CSMresearch/Rhone_Glacier/Rhone_Glacier_AWS_Final/20200803_070000.000-20200803_090000.000/codes/input/DAS_data/idas2_UTC_20200803_070250.542_rhone1khz.hdf5', '/Users/rachelwillis/myDocuments/CSMresearch/Rhone_Glacier/Rhone_Glacier_AWS_Final/20200803_070000.000-20200803_090000.000/codes/input/DAS_data/idas2_UTC_20200803_070320.542_rhone1khz.hdf5', '/Users/rachelwillis/myDocuments/CSMresearch/Rhone_Glacier/Rhone_Glacier_AWS_Final/20200803_070000.000-20200803_090000.000/codes/input/DAS_data/idas2_UTC_20200803_070350.542_rhone1khz.hdf5']\n",
      "✔ success\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    for file_id in range(0, nr_files - nr_files_to_load, nr_files_to_process):\n",
    "        print(f'Processing File ID: {file_id}')\n",
    "\n",
    "        # Load Data\n",
    "        st = das_reader(files_list[file_id:file_id + nr_files_to_load], stream=False,\n",
    "                    channels=channels_to_read_new, h5type='idas2', debug=True)\n",
    "\n",
    "        if st[0].shape[0] != 90000:\n",
    "            continue\n",
    "\n",
    "        sampling_rate = int(st[2]['sampling_frequency_Hz'])\n",
    "        starttime = UTCDateTime(st[2]['starttime'])\n",
    "                    \n",
    "        plotChRange(st[0], fs=250, clipPerc=99.97, title = f'{starttime}', outfile=f'{starttime}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaed4b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
